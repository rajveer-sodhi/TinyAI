
Epoch 1/15
----------------------------------------
  Batch 50: Loss=8.6110, Acc=0.0253
  Batch 100: Loss=8.0940, Acc=0.0645
  Batch 150: Loss=7.6113, Acc=0.0577
  Batch 200: Loss=7.2928, Acc=0.0377
  Batch 250: Loss=6.9648, Acc=0.0470
  Batch 300: Loss=6.6998, Acc=0.0589
  Batch 350: Loss=6.3882, Acc=0.0466
  Batch 400: Loss=6.2248, Acc=0.0621
  Batch 450: Loss=6.1751, Acc=0.0661
  Batch 500: Loss=5.8802, Acc=0.0635
  Batch 550: Loss=6.1685, Acc=0.0797
  Batch 600: Loss=6.0352, Acc=0.0798
  Batch 650: Loss=5.9724, Acc=0.0934
  Batch 700: Loss=5.8225, Acc=0.1193
  Batch 750: Loss=5.9317, Acc=0.1220
  Batch 800: Loss=6.0025, Acc=0.1220
  Batch 850: Loss=5.7995, Acc=0.1592
  Batch 900: Loss=5.7328, Acc=0.1477
  Batch 950: Loss=5.6360, Acc=0.1873
  Batch 1000: Loss=5.6677, Acc=0.1734
  Batch 1050: Loss=5.4974, Acc=0.1724
  Batch 1100: Loss=5.5826, Acc=0.1795
  Batch 1150: Loss=5.4306, Acc=0.1557
  Batch 1200: Loss=5.2997, Acc=0.2118
  Batch 1250: Loss=5.2122, Acc=0.1926
  Batch 1300: Loss=5.3374, Acc=0.2296
  Batch 1350: Loss=5.1668, Acc=0.1925
  Batch 1400: Loss=5.1684, Acc=0.1774

  Train Loss: 6.1699, Train Acc: 0.1178
  Val Loss: 5.0506, Val Acc: 0.2170
  âœ“ Saved best model (val_loss=5.0506)

Epoch 2/15
----------------------------------------
  Batch 50: Loss=4.9601, Acc=0.2303
  Batch 100: Loss=4.8432, Acc=0.2412
  Batch 150: Loss=4.7272, Acc=0.2201
  Batch 200: Loss=4.9567, Acc=0.2425
  Batch 250: Loss=4.9420, Acc=0.2302
  Batch 300: Loss=4.7421, Acc=0.2623
  Batch 350: Loss=4.7960, Acc=0.2358
  Batch 400: Loss=4.9938, Acc=0.2379
  Batch 450: Loss=4.7606, Acc=0.2467
  Batch 500: Loss=4.8443, Acc=0.2545
  Batch 550: Loss=4.9508, Acc=0.2398
