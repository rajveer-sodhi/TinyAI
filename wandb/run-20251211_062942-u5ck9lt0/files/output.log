
Epoch 1/15
----------------------------------------
  Batch 50: Loss=9.2116, Acc=0.0718, AnsAcc=0.0366
  Batch 100: Loss=8.7348, Acc=0.0836, AnsAcc=0.0750
  Batch 150: Loss=8.2433, Acc=0.0795, AnsAcc=0.0691
  Batch 200: Loss=7.8219, Acc=0.0721, AnsAcc=0.0662
  Batch 250: Loss=7.4224, Acc=0.0673, AnsAcc=0.0571
  Batch 300: Loss=7.2071, Acc=0.0640, AnsAcc=0.0450
  Batch 350: Loss=7.0206, Acc=0.0599, AnsAcc=0.0540
  Batch 400: Loss=6.7000, Acc=0.0689, AnsAcc=0.0651
  Batch 450: Loss=6.5934, Acc=0.0739, AnsAcc=0.0581
  Batch 500: Loss=6.3282, Acc=0.0741, AnsAcc=0.0565
  Batch 550: Loss=6.4286, Acc=0.0723, AnsAcc=0.0688
  Batch 600: Loss=6.2987, Acc=0.0740, AnsAcc=0.0737
  Batch 650: Loss=6.3352, Acc=0.0765, AnsAcc=0.0707
  Batch 700: Loss=6.1415, Acc=0.0876, AnsAcc=0.0769

  Train Loss: 7.1964, Train Acc: 0.0733, Train AnsAcc: 0.0634
  Val Loss: 6.1277, Val Acc: 0.0780, Val AnsAcc: 0.0754
  âœ“ Saved best model (val_loss=6.1277)

Epoch 2/15
----------------------------------------
  Batch 50: Loss=6.0768, Acc=0.1150, AnsAcc=0.0716
  Batch 100: Loss=5.8169, Acc=0.1640, AnsAcc=0.1061
  Batch 150: Loss=5.9603, Acc=0.1391, AnsAcc=0.0997
  Batch 200: Loss=5.8499, Acc=0.1832, AnsAcc=0.2625
  Batch 250: Loss=5.9104, Acc=0.1866, AnsAcc=0.1746
  Batch 300: Loss=5.9159, Acc=0.1777, AnsAcc=0.1581
  Batch 350: Loss=5.7867, Acc=0.1654, AnsAcc=0.1380
  Batch 400: Loss=5.6145, Acc=0.1734, AnsAcc=0.1403
