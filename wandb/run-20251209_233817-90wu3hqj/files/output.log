
Epoch 1/20
----------------------------------------
  Batch 50: Loss=7.6143, Acc=0.0453
  Batch 100: Loss=6.4678, Acc=0.0622
  Batch 150: Loss=5.9601, Acc=0.1148
  Batch 200: Loss=5.6618, Acc=0.1617
  Batch 250: Loss=5.4006, Acc=0.1831
  Batch 300: Loss=5.3245, Acc=0.2087
  Batch 350: Loss=4.9541, Acc=0.2191
  Batch 400: Loss=4.8040, Acc=0.2394
  Batch 450: Loss=4.6369, Acc=0.2499
  Batch 500: Loss=4.6829, Acc=0.2549

  Train Loss: 5.6647, Train Acc: 0.1742
  Val Loss: 4.4644, Val Acc: 0.2623
  ✓ Saved best model (val_loss=4.4644)

Epoch 2/20
----------------------------------------
  Batch 50: Loss=4.3571, Acc=0.2684
  Batch 100: Loss=4.3038, Acc=0.2720
  Batch 150: Loss=4.2586, Acc=0.2774
  Batch 200: Loss=4.3626, Acc=0.2724
  Batch 250: Loss=3.9785, Acc=0.3141
  Batch 300: Loss=4.1528, Acc=0.2863
  Batch 350: Loss=4.0621, Acc=0.2842
  Batch 400: Loss=4.1407, Acc=0.2793
  Batch 450: Loss=3.9375, Acc=0.2921
  Batch 500: Loss=3.8748, Acc=0.3030

  Train Loss: 4.1325, Train Acc: 0.2866
  Val Loss: 3.8398, Val Acc: 0.3150
  ✓ Saved best model (val_loss=3.8398)

Epoch 3/20
----------------------------------------
  Batch 50: Loss=3.7942, Acc=0.3120
  Batch 100: Loss=3.7572, Acc=0.3012
  Batch 150: Loss=3.6078, Acc=0.3325
  Batch 200: Loss=3.5663, Acc=0.3322
  Batch 250: Loss=3.8184, Acc=0.3226
  Batch 300: Loss=3.5944, Acc=0.3242
  Batch 350: Loss=3.7741, Acc=0.3406
  Batch 400: Loss=3.5287, Acc=0.3568
  Batch 450: Loss=3.5228, Acc=0.3502
  Batch 500: Loss=3.5162, Acc=0.3642

  Train Loss: 3.6342, Train Acc: 0.3374
  Val Loss: 3.3986, Val Acc: 0.3728
  ✓ Saved best model (val_loss=3.3986)

Epoch 4/20
----------------------------------------
  Batch 50: Loss=3.4634, Acc=0.3595
  Batch 100: Loss=3.4426, Acc=0.3630
  Batch 150: Loss=3.4008, Acc=0.3648
  Batch 200: Loss=3.2491, Acc=0.3886
  Batch 250: Loss=3.1892, Acc=0.4155
  Batch 300: Loss=3.3349, Acc=0.4017
  Batch 350: Loss=2.8925, Acc=0.4592
  Batch 400: Loss=2.7014, Acc=0.4911
  Batch 450: Loss=2.8815, Acc=0.4515
  Batch 500: Loss=2.6700, Acc=0.4873

  Train Loss: 3.1125, Train Acc: 0.4186
  Val Loss: 2.4984, Val Acc: 0.5471
  ✓ Saved best model (val_loss=2.4984)

Epoch 5/20
----------------------------------------
  Batch 50: Loss=2.4971, Acc=0.5392
  Batch 100: Loss=2.1007, Acc=0.6175
  Batch 150: Loss=1.9696, Acc=0.6590
  Batch 200: Loss=1.6667, Acc=0.7213
  Batch 250: Loss=1.7340, Acc=0.7276
  Batch 300: Loss=1.3715, Acc=0.7871
  Batch 350: Loss=1.3693, Acc=0.7959
  Batch 400: Loss=1.2589, Acc=0.8007
  Batch 450: Loss=1.2988, Acc=0.7982
  Batch 500: Loss=1.1805, Acc=0.8206

  Train Loss: 1.6239, Train Acc: 0.7284
  Val Loss: 0.8862, Val Acc: 0.8677
  ✓ Saved best model (val_loss=0.8862)

Epoch 6/20
----------------------------------------
  Batch 50: Loss=0.7717, Acc=0.8877
  Batch 100: Loss=0.8109, Acc=0.8804
  Batch 150: Loss=0.8546, Acc=0.8822
  Batch 200: Loss=0.8391, Acc=0.8885
  Batch 250: Loss=0.6765, Acc=0.9112
  Batch 300: Loss=0.6696, Acc=0.9119
  Batch 350: Loss=0.7014, Acc=0.9059
  Batch 400: Loss=0.6402, Acc=0.9129
  Batch 450: Loss=0.5886, Acc=0.9229
  Batch 500: Loss=0.5591, Acc=0.9253

  Train Loss: 0.7520, Train Acc: 0.8937
  Val Loss: 0.5138, Val Acc: 0.9318
  ✓ Saved best model (val_loss=0.5138)

Epoch 7/20
----------------------------------------
  Batch 50: Loss=0.6472, Acc=0.9100
  Batch 100: Loss=0.5645, Acc=0.9235
  Batch 150: Loss=0.4752, Acc=0.9408
  Batch 200: Loss=0.5063, Acc=0.9334
  Batch 250: Loss=0.4136, Acc=0.9480
  Batch 300: Loss=0.5364, Acc=0.9230
  Batch 350: Loss=0.3963, Acc=0.9507
  Batch 400: Loss=0.4686, Acc=0.9419
  Batch 450: Loss=0.4318, Acc=0.9437
  Batch 500: Loss=0.5047, Acc=0.9310

  Train Loss: 0.4811, Train Acc: 0.9351
  Val Loss: 0.3497, Val Acc: 0.9562
  ✓ Saved best model (val_loss=0.3497)

Epoch 8/20
----------------------------------------
  Batch 50: Loss=0.3571, Acc=0.9546
  Batch 100: Loss=0.3449, Acc=0.9492
  Batch 150: Loss=0.4092, Acc=0.9468
  Batch 200: Loss=0.4048, Acc=0.9456
  Batch 250: Loss=0.3707, Acc=0.9509
  Batch 300: Loss=0.3741, Acc=0.9436
  Batch 350: Loss=0.2844, Acc=0.9642
  Batch 400: Loss=0.1839, Acc=0.9795
  Batch 450: Loss=0.3055, Acc=0.9631
  Batch 500: Loss=0.2925, Acc=0.9605

  Train Loss: 0.3321, Train Acc: 0.9563
  Val Loss: 0.2476, Val Acc: 0.9712
  ✓ Saved best model (val_loss=0.2476)

Epoch 9/20
----------------------------------------
  Batch 50: Loss=0.1569, Acc=0.9862
  Batch 100: Loss=0.2018, Acc=0.9764
  Batch 150: Loss=0.1993, Acc=0.9740
  Batch 200: Loss=0.2347, Acc=0.9687
  Batch 250: Loss=0.2239, Acc=0.9708
  Batch 300: Loss=0.2014, Acc=0.9773
  Batch 350: Loss=0.2396, Acc=0.9737
  Batch 400: Loss=0.1249, Acc=0.9856
  Batch 450: Loss=0.1143, Acc=0.9870
  Batch 500: Loss=0.2287, Acc=0.9705

  Train Loss: 0.2263, Train Acc: 0.9722
  Val Loss: 0.1851, Val Acc: 0.9806
  ✓ Saved best model (val_loss=0.1851)

Epoch 10/20
----------------------------------------
  Batch 50: Loss=0.1922, Acc=0.9805
  Batch 100: Loss=0.1705, Acc=0.9769
  Batch 150: Loss=0.1412, Acc=0.9855
  Batch 200: Loss=0.2343, Acc=0.9778
  Batch 250: Loss=0.1506, Acc=0.9850
  Batch 300: Loss=0.1919, Acc=0.9810
  Batch 350: Loss=0.1339, Acc=0.9852
  Batch 400: Loss=0.1650, Acc=0.9804
  Batch 450: Loss=0.1580, Acc=0.9810
  Batch 500: Loss=0.1374, Acc=0.9837

  Train Loss: 0.1605, Train Acc: 0.9816
  Val Loss: 0.1454, Val Acc: 0.9864
  ✓ Saved best model (val_loss=0.1454)

Epoch 11/20
----------------------------------------
  Batch 50: Loss=0.1479, Acc=0.9809
  Batch 100: Loss=0.0954, Acc=0.9928
  Batch 150: Loss=0.1072, Acc=0.9899
  Batch 200: Loss=0.1504, Acc=0.9782
  Batch 250: Loss=0.1128, Acc=0.9905
  Batch 300: Loss=0.1450, Acc=0.9849
  Batch 350: Loss=0.1594, Acc=0.9817
  Batch 400: Loss=0.1061, Acc=0.9887
  Batch 450: Loss=0.1158, Acc=0.9881
  Batch 500: Loss=0.0666, Acc=0.9948

  Train Loss: 0.1196, Train Acc: 0.9872
  Val Loss: 0.1201, Val Acc: 0.9895
  ✓ Saved best model (val_loss=0.1201)

Epoch 12/20
----------------------------------------
  Batch 50: Loss=0.1412, Acc=0.9863
  Batch 100: Loss=0.1328, Acc=0.9846
  Batch 150: Loss=0.0968, Acc=0.9915
  Batch 200: Loss=0.1017, Acc=0.9921
  Batch 250: Loss=0.0763, Acc=0.9917
  Batch 300: Loss=0.0940, Acc=0.9915
  Batch 350: Loss=0.0512, Acc=0.9969
  Batch 400: Loss=0.0996, Acc=0.9881
  Batch 450: Loss=0.0764, Acc=0.9924
  Batch 500: Loss=0.0601, Acc=0.9976

  Train Loss: 0.0914, Train Acc: 0.9908
  Val Loss: 0.1017, Val Acc: 0.9920
  ✓ Saved best model (val_loss=0.1017)

Epoch 13/20
----------------------------------------
  Batch 50: Loss=0.0400, Acc=0.9982
  Batch 100: Loss=0.0567, Acc=0.9944
  Batch 150: Loss=0.0417, Acc=0.9941
  Batch 200: Loss=0.1244, Acc=0.9862
  Batch 250: Loss=0.1077, Acc=0.9866
  Batch 300: Loss=0.0604, Acc=0.9935
  Batch 350: Loss=0.0756, Acc=0.9913
  Batch 400: Loss=0.0722, Acc=0.9937
  Batch 450: Loss=0.0886, Acc=0.9913
  Batch 500: Loss=0.0328, Acc=0.9969

  Train Loss: 0.0707, Train Acc: 0.9933
  Val Loss: 0.0898, Val Acc: 0.9931
  ✓ Saved best model (val_loss=0.0898)

Epoch 14/20
----------------------------------------
  Batch 50: Loss=0.0618, Acc=0.9924
  Batch 100: Loss=0.0633, Acc=0.9922
  Batch 150: Loss=0.0457, Acc=0.9972
  Batch 200: Loss=0.0560, Acc=0.9969
  Batch 250: Loss=0.0625, Acc=0.9944
  Batch 300: Loss=0.0621, Acc=0.9952
  Batch 350: Loss=0.0355, Acc=0.9974
  Batch 400: Loss=0.0519, Acc=0.9958
  Batch 450: Loss=0.0178, Acc=0.9989
  Batch 500: Loss=0.0494, Acc=0.9979

  Train Loss: 0.0553, Train Acc: 0.9950
  Val Loss: 0.0800, Val Acc: 0.9944
  ✓ Saved best model (val_loss=0.0800)

Epoch 15/20
----------------------------------------
  Batch 50: Loss=0.0408, Acc=0.9967
  Batch 100: Loss=0.0506, Acc=0.9956
  Batch 150: Loss=0.0449, Acc=0.9961
  Batch 200: Loss=0.0508, Acc=0.9963
  Batch 250: Loss=0.0557, Acc=0.9942
  Batch 300: Loss=0.0440, Acc=0.9935
  Batch 350: Loss=0.0364, Acc=0.9967
  Batch 400: Loss=0.0216, Acc=0.9989
  Batch 450: Loss=0.0779, Acc=0.9892
  Batch 500: Loss=0.0243, Acc=0.9973

  Train Loss: 0.0435, Train Acc: 0.9962
  Val Loss: 0.0732, Val Acc: 0.9951
  ✓ Saved best model (val_loss=0.0732)

Epoch 16/20
----------------------------------------
  Batch 50: Loss=0.0402, Acc=0.9969
  Batch 100: Loss=0.0469, Acc=0.9983
  Batch 150: Loss=0.0234, Acc=0.9983
  Batch 200: Loss=0.0331, Acc=0.9983
  Batch 250: Loss=0.0200, Acc=0.9979
  Batch 300: Loss=0.0321, Acc=0.9984
  Batch 350: Loss=0.0244, Acc=0.9974
  Batch 400: Loss=0.0227, Acc=0.9963
  Batch 450: Loss=0.0203, Acc=0.9986
  Batch 500: Loss=0.0451, Acc=0.9960

  Train Loss: 0.0346, Train Acc: 0.9973
  Val Loss: 0.0679, Val Acc: 0.9956
  ✓ Saved best model (val_loss=0.0679)

Epoch 17/20
----------------------------------------
  Batch 50: Loss=0.0275, Acc=0.9976
  Batch 100: Loss=0.0413, Acc=0.9980
  Batch 150: Loss=0.0230, Acc=0.9986
  Batch 200: Loss=0.0190, Acc=0.9989
  Batch 250: Loss=0.0167, Acc=0.9994
  Batch 300: Loss=0.0270, Acc=0.9981
  Batch 350: Loss=0.0193, Acc=0.9987
  Batch 400: Loss=0.0253, Acc=0.9986
  Batch 450: Loss=0.0143, Acc=0.9997
  Batch 500: Loss=0.0101, Acc=0.9989

  Train Loss: 0.0274, Train Acc: 0.9982
  Val Loss: 0.0639, Val Acc: 0.9959
  ✓ Saved best model (val_loss=0.0639)

Epoch 18/20
----------------------------------------
  Batch 50: Loss=0.0229, Acc=0.9989
  Batch 100: Loss=0.0282, Acc=0.9982
  Batch 150: Loss=0.0289, Acc=0.9992
  Batch 200: Loss=0.0184, Acc=0.9986
  Batch 250: Loss=0.0213, Acc=0.9981
  Batch 300: Loss=0.0213, Acc=0.9989
  Batch 350: Loss=0.0303, Acc=0.9991
  Batch 400: Loss=0.0051, Acc=1.0000
  Batch 450: Loss=0.0247, Acc=0.9978
  Batch 500: Loss=0.0255, Acc=0.9972

  Train Loss: 0.0221, Train Acc: 0.9987
  Val Loss: 0.0613, Val Acc: 0.9961
  ✓ Saved best model (val_loss=0.0613)

Epoch 19/20
----------------------------------------
  Batch 50: Loss=0.0212, Acc=0.9981
  Batch 100: Loss=0.0234, Acc=0.9995
  Batch 150: Loss=0.0198, Acc=0.9982
  Batch 200: Loss=0.0169, Acc=0.9994
  Batch 250: Loss=0.0206, Acc=0.9991
  Batch 300: Loss=0.0270, Acc=0.9985
  Batch 350: Loss=0.0168, Acc=0.9988
  Batch 400: Loss=0.0104, Acc=1.0000
  Batch 450: Loss=0.0222, Acc=0.9987
  Batch 500: Loss=0.0219, Acc=0.9995

  Train Loss: 0.0177, Train Acc: 0.9990
  Val Loss: 0.0588, Val Acc: 0.9961
  ✓ Saved best model (val_loss=0.0588)

Epoch 20/20
----------------------------------------
  Batch 50: Loss=0.0285, Acc=0.9997
  Batch 100: Loss=0.0083, Acc=1.0000
  Batch 150: Loss=0.0122, Acc=0.9994
  Batch 200: Loss=0.0125, Acc=0.9995
  Batch 250: Loss=0.0175, Acc=0.9992
  Batch 300: Loss=0.0206, Acc=0.9994
  Batch 350: Loss=0.0140, Acc=0.9997
  Batch 400: Loss=0.0081, Acc=0.9997
  Batch 450: Loss=0.0176, Acc=0.9992
  Batch 500: Loss=0.0080, Acc=0.9994

  Train Loss: 0.0144, Train Acc: 0.9991
  Val Loss: 0.0569, Val Acc: 0.9962
  ✓ Saved best model (val_loss=0.0569)

✓ Training complete. Best validation loss: 0.0569
